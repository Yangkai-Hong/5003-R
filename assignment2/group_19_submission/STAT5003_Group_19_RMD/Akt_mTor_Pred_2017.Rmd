---
title: "Stat5003 - Assignment 2: Predicting Novel Kinase-substrates of Akt and mTOR"
author: "Group 19"
date: "30 October 2017"
output: 
  html_document:
    toc: true

---

#Description
In this project, we will aim to apply classification techniques for predicting novel kinase-substrates of Akt and mTOR by using and/or extracting learning features from temporal phosphoproteomics data (and, if possible, combining these features with kinase-substrate recognition sequence motif). 

In summary, we try 3 different approaches and each produces result that's comparable to the prediction made in 2016.

Group 19 members:
<li> Anqi Feng (470171497)
<li> Na Liu (470327120)
<li> Kurniawan Pranogo Panjiarto (460473970)
<li> Shangzhou Wang (308047990)
<li> Yangkai Hong (470231528)


## 1. Load the packages needed for the Project

```{r setup, include=TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(stringr)
library(tidytext)
library(recipes)
library(FFTrees)
library(tibble)
library(tidyselect)
library(rlang)
library(Rtsne)
library(readxl)
library(dbscan)

## create df selection function
model_df <- function(df, cols) {
            df <- select(df, cols) 
            return(df)
}
```

## 2. Load the Data and Clean

### 2.1 Load the raw text data for the project
```{r rawdata, message=FALSE, warning=FALSE}
ins <- read_tsv("data/InsulinPhospho.txt")
col <- c("identifier", "motif", "p_fold_avg", "p_auc", "p_15s", "p_30s", "p_1m", "p_2m",
         "p_5m", "p_10m", "p_20m", "p_60m", "p_insulin_1", "p_ly", "p_insulin_2","p_mk")
colnames(ins) <-  col

akt <- read_tsv("data/Akt_substrates.txt", col_names = FALSE) %>% dplyr::rename(identifier = X1) %>% 
  mutate(id = identifier) %>% 
  separate(id, c("symbol", "site","rem"), sep = ";") %>% select(-rem)
mtor <- read_tsv("data/mTOR_substrates.txt", col_names = FALSE) %>% dplyr::rename(identifier = X1) %>% 
  mutate(id = identifier) %>% 
  separate(id, c("symbol", "site","rem"), sep = ";") %>% select(-rem)

```

### 2.2 Load and Clean 2016 Prediction Result 
In addition to the raw data, the prediction results from 2016 is also loaded. The 2016 prediction result from Excel has some gene format issues, such as it is displayed as a date format instead of legitimate gene format. 

```{r pred2016, message=FALSE, warning=FALSE}
## get site from the raw data imported above. The idea is try to use motif to match gene id
## if there is 2 site with the same motif then we treat it separately
site_2017 <- ins %>% select(identifier, motif) %>% 
  separate(identifier, c("genesymbol", "site", "rem"), sep = ";", remove = F) %>% 
  select(-rem, -genesymbol) %>% unite(site_motif, site:motif, sep ="|") %>% group_by(site_motif) %>% 
  dplyr::mutate(rown = n()) %>% ungroup()

site_2017.1 <- site_2017 %>% filter(rown == 1) ## motifs have a single gene site
site_2017.2 <- site_2017 %>% filter(rown > 1) ## motifs have multiple gene sites

## load 2016 prediction from Excel
pred_16_akt <- read_excel("Prediction_2016.xlsx", sheet = "Akt_prediction")
names(pred_16_akt) <- make.names(names(pred_16_akt))
pred_16_mtor <- read_excel("Prediction_2016.xlsx", sheet = "mTOR_prediction")
names(pred_16_mtor) <- make.names(names(pred_16_mtor))

## tidy akt 2016 prediction with identifier same as this year
pred_16_akt <- pred_16_akt %>% select(Phosphorylation.site, Sequence.window, 
                                      Full.model.predict, Motif.predict, Phosphoproteome.predict) %>% 
    unite(site_motif, Phosphorylation.site:Sequence.window, sep = "|") %>% group_by(site_motif) %>% 
    summarise(Full.model.predict = max(Full.model.predict), 
            Motif.predict = max(Motif.predict), 
            Phosphoproteome.predict = max(Phosphoproteome.predict))

akt_prediction_2016.1 <- site_2017.1 %>% inner_join(pred_16_akt) %>% select(-rown) %>% 
  separate(site_motif, c("site", "motif")) %>% select(-site) %>% 
  mutate(akt_full = Full.model.predict > 0.5, 
         akt_motif = Motif.predict > 0.5,
         akt_pp = Phosphoproteome.predict > 0.5)

akt_prediction_2016.2 <- site_2017.2 %>% inner_join(pred_16_akt) %>% select(-rown) %>% 
  separate(site_motif, c("site", "motif")) %>% select(-site) %>% 
  mutate(akt_full = Full.model.predict > 0.5, 
         akt_motif = Motif.predict > 0.5,
         akt_pp = Phosphoproteome.predict > 0.5)

akt_prediction_2016 <- bind_rows(akt_prediction_2016.1, akt_prediction_2016.2)

## write_csv(akt_prediction_2016, "processed_akt_prediction_2016.csv")

## tidy motr 2016 prediction with identifier same as this year
pred_16_mtor <- pred_16_mtor %>% select(Phosphorylation.site, Sequence.window, 
                                      Full.model.predict, Motif.predict, Phosphoproteome.predict) %>% 
  unite(site_motif, Phosphorylation.site:Sequence.window, sep = "|") %>% group_by(site_motif) %>% 
  summarise(Full.model.predict = max(Full.model.predict), 
            Motif.predict = max(Motif.predict), 
            Phosphoproteome.predict = max(Phosphoproteome.predict))

mtor_prediction_2016.1 <- site_2017.1 %>% inner_join(pred_16_mtor) %>% select(-rown) %>% 
  separate(site_motif, c("site", "motif")) %>% select(-site) %>% 
  mutate(mtor_full = Full.model.predict > 0.5, 
         mtor_motif = Motif.predict > 0.5,
         mtor_pp = Phosphoproteome.predict > 0.5)

mtor_prediction_2016.2 <- site_2017.2 %>% inner_join(pred_16_mtor) %>% select(-rown) %>% 
  separate(site_motif, c("site", "motif")) %>% select(-site) %>% 
  mutate(mtor_full = Full.model.predict > 0.5, 
         mtor_motif = Motif.predict > 0.5,
         mtor_pp = Phosphoproteome.predict > 0.5)

mtor_prediction_2016 <- bind_rows(mtor_prediction_2016.1, mtor_prediction_2016.2)

## write_csv(mtor_prediction_2016, "processed_mtor_prediction_2016.csv")

```
## 3. Variable Augumentation and Explorative Analysis

### 3.1 Turn Motif Character Symbol to TD-IDF (NLP)

The idea of turn the motif character symbol into TD-IDF value comes after a few exploratory analysis after position categorical analysis, one-hot dummy variable encoding etc.. After a few try we found that TD-IDF is a rather feasible way to numerically represent motif position values.

```{r motif, message=FALSE, warning=FALSE}
## motif based analysis:
## 1. separate the sequence to 1 character
ins_motif <- ins %>% select(identifier, motif) %>% mutate(gene_seq = motif) %>% 
  unnest_tokens(word, motif, token = stringr::str_split, pattern = "", to_lower = F) %>% group_by(identifier) %>% 
  mutate(coln = paste0("pos", str_sub(100 + row_number(), -2, -1))) %>% ungroup() 

ins_motif.1 <- ins_motif %>% group_by(coln, word) %>% summarise(n = n()) %>% 
  mutate(log_n = log(n))

total_w <- ins_motif.1 %>% group_by(coln) %>% summarise(total = sum(n))

## Turn motif character into the TF-IDF value 
ins_motif.1 <- inner_join(ins_motif.1, total_w, by = c("coln" = "coln")) %>%  
  bind_tf_idf(word, coln, n) %>% select(-total)

## Check the TD-IDF distribution
ggplot(filter(ins_motif.1, coln != "pos07"), aes(x = coln, y = tf_idf)) +
  geom_boxplot() +
  geom_jitter(position = position_jitter(width = .35), alpha = 0.2) +
  theme_classic() +
  labs(title = "Sequence Motif TF-IDF Value Distribuion", x = "Motif Position",
       y = "Motif TF-IDF Value") +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5, size = 14, color = "darkblue"),
        axis.text = element_text(size = 11, color = "blue"),
        axis.title = element_text(size = 12, color = "darkblue"))

```

### 3.2 N-gram operation for motif sequence (Variable Augumentation)

Based on the character position in motif, we came up some idea to augment the motif information by utilizing the NLP n-gram concept. Basically, we try to understand if any 2 position combination could impact the analysis. For simplicity, we only used, 2-gram and 2-gram with skip 1 symbol in the middle to further generate 23 variables.

```{r ngram, message=FALSE, warning=FALSE}

# ins_motif.2 <- ins_motif %>% select(identifier, word) %>%
#   mutate(word = ifelse(word == "_", 9, word)) %>% ## need to replace _ to something as _ is a wildcard
#   group_by(identifier) %>% mutate(motif = paste(word, collapse = " ")) %>%
#   ungroup() %>% select(identifier, motif) %>%
#   unique() %>%
#   unnest_tokens(ngram, motif, token = "skip_ngrams", n = 2, k = 1, to_lower = F)
# write_csv(ins_motif.2 , "ngram_motif_akt.csv")

ins_motif.2 <- read_csv("ngram_motif_akt.csv")

# ins_motif.2.m <- ins_motif.2 %>% select(motif) %>%
#   unique() %>%
#   unnest_tokens(ngram, motif, token = "skip_ngrams", n = 2, k = 1, to_lower = F, drop = FALSE)

ins_motif.2 <- ins_motif.2 %>% group_by(identifier) %>%
  mutate(coln = 100 + row_number()) %>% ungroup() %>%
  mutate(coln = ifelse(coln < 112,
                       paste0("skip1_pos", str_sub(coln, -2, -1)),
                       paste0("2gram_pos", str_sub(coln - 11, -2, -1))))

# for skip 1 2 gram
ins_motif.skip <- ins_motif.2 %>%
  filter(str_sub(coln, 1, 5) == "skip1") %>%
  group_by(coln, ngram) %>% summarise(n = n())
total_w.skip <- ins_motif.skip %>% group_by(coln) %>% summarise(total = sum(n))

ins_motif.skip <- inner_join(ins_motif.skip, total_w.skip, by = c("coln" = "coln")) %>%
  bind_tf_idf(ngram, coln, n) %>%
  select(coln, ngram, tf_idf)

# for 2 gram no skip
ins_motif.ngram <- ins_motif.2 %>%
  filter(str_sub(coln, 1, 5) == "2gram") %>%
  group_by(coln, ngram) %>% summarise(n = n())
total_w.ngram <- ins_motif.ngram %>% group_by(coln) %>% summarise(total = sum(n))

ins_motif.ngram <- inner_join(ins_motif.ngram, total_w.ngram, by = c("coln" = "coln")) %>%
  bind_tf_idf(ngram, coln, n) %>%
  select(coln, ngram, tf_idf)

ins_motif.m <- ins_motif %>% spread(coln, word)
## single character tf-idf
ins_motif.t <- ins_motif %>% select(-gene_seq) %>% inner_join(ins_motif.1) %>%
  select(-word) %>% mutate(coln = paste0("ti_", coln)) %>%
  spread(coln, tf_idf)

## skip 1 sequence 2gram, like poistion 1,3 or 2, 4, or 3, 5 etc
ins_motif.s <- ins_motif.2 %>%
  filter(str_sub(coln, 1, 5) == "skip1") %>%
  inner_join(ins_motif.skip) %>%
  select(-ngram) %>% mutate(coln = paste0("ti_", coln)) %>%
  spread(coln, tf_idf)

# ngram for 2
ins_motif.n <- ins_motif.2 %>%
  filter(str_sub(coln, 1, 5) == "2gram") %>%
  inner_join(ins_motif.ngram) %>%
  select(-ngram) %>% mutate(coln = paste0("ti_", coln)) %>%
  spread(coln, tf_idf)

# join all tf-idf together
ins_motif <- inner_join(ins_motif.m, ins_motif.t) %>%
  inner_join(ins_motif.s) %>% inner_join(ins_motif.n)

akt_l <- select(akt, identifier) %>% mutate(is_akt = 1)
mtor_l <- select(mtor, identifier) %>% mutate(is_mtor = 1)

ins_df <- ins_motif %>% inner_join(ins) %>% select(-gene_seq, -motif) %>%
  mutate(p_ins_1_x_ly = p_insulin_1 * p_ly, p_ins_2_x_mk = p_insulin_2 * p_mk) %>%
  left_join(akt_l, by = c("identifier" = "identifier")) %>%
  left_join(mtor_l, by = c("identifier" = "identifier")) %>%
  mutate(is_akt = ifelse(is.na(is_akt), 0, 1), is_mtor = ifelse(is.na(is_mtor), 0, 1))
  
# write_csv(ins_df, "insulin_preprocessed_data_new.csv")

ins_df <- read_csv("insulin_preprocessed_data_new.csv")
```

###3.3 calculate variance & PSSM 
```{r}
dt <- read.csv("data/InsulinPhospho.txt", sep = "\t")
akt <- read.csv("data/Akt_substrates.txt", header = FALSE)
mtor <- read.csv("data/mTOR_substrates.txt", header = FALSE)

ins_df$p_X.Var <- 0
ins_df$p_PSSM <- 0

labels <- data.frame(matrix(NA,nrow=nrow(dt),ncol=2))
colnames(labels) <- c("Akt","mTOR")
for (i in akt[[1]]) {
  idx <- which(apply(dt, 1, function(x) any(grepl(i, x))))
  labels$Akt[idx] <- 1
  labels$mTOR[idx] <- 0
}
for (i in mtor[[1]]) {
  idx <- which(apply(dt, 1, function(x) any(grepl(i, x))))
  labels$Akt[idx] <- 0
  labels$mTOR[idx] <- 1
}

# variance of the 8 observations
for(i in 1:nrow(dt)) {
  ins_df$p_X.Var[i] <- var(as.numeric(dt[i,5:12]))
}

# PSSM
protein <- c("A","C","D","E","F","G","H","I","K","L","M","N","P","Q","R","S","T","V","W","Y")
PFM <- matrix(0,nrow = 20, ncol = 13)
for(motif in dt[,2]) {
  ctr <- 1
  for (x in strsplit(motif, "")[[1]]) {
    if (x != "_") {
      pos <- match(x, protein)
      PFM[pos,ctr] <- PFM[pos,ctr] + 1
    }
    ctr <- ctr + 1
  }
}

PPM <- PFM %*% diag(1 / colSums(PFM))
bk <- rowSums(PFM) / sum(PFM)
PWM <- log2(PPM / bk)

idx <- 1
for(motif in dt[,2]) {
  ctr <- 1
  total <- 0
  for (x in strsplit(motif, "")[[1]]) {
    if (x != "_") {
      pos <- match(x, protein)
      total <- total + PWM[pos, ctr]
    }
    ctr <- ctr + 1
  }
  ins_df$p_PSSM[idx] <- total
  idx <- idx + 1
}
```



## 4. Use a Decition Tree Model to Identifiy the most Posible Negative Observations

Given that we only know a handful true positive Akt or mTor sites, our goal is first to use this information to identify those sites with most probability to be negative.

We built a decision tree model to select the tree model with the sensitivity to be 100% to make sure that our selected sites to be most probable negative.

We run the same model multiple times (here 5 times) and we define those sites never predicted as positive to be regarded as negative sites for later user.
```{r getneg, message=FALSE, warning=FALSE}
## feature selection
vars <- names(ins_df)
id <- vars_select(vars, identifier) # id field
motif_ch <- vars_select(vars, starts_with("pos")) # motif symbol columns
motif_ti <- vars_select(vars, starts_with("ti_")) # motif ti-idf fields of motif symbol
insulin_dy <- vars_select(vars, starts_with("p_")) # fields for insuline fold change values
cl_akt <- vars_select(vars, is_akt)
cl_mtor <- vars_select(vars, is_mtor)

df_motif_ch_akt <- c(id, motif_ch, cl_akt) ## motif character data frame
df_motif_ti_akt <- c(id, motif_ti, cl_akt) ## motif ti-idf data frame
df_motif_akt <- c(id, motif_ch, motif_ti, cl_akt) ## motif ti-idf data frame
df_motif_ch_mtor <- c(id, motif_ch, cl_mtor) ## motif character data frame
df_motif_ti_mtor <- c(id, motif_ti, cl_mtor) ## motif ti-idf data frame
df_motif_mtor <- c(id, motif_ch, motif_ti, cl_mtor) ## motif character data frame
df_insulin_akt <- c(id, insulin_dy, cl_akt) ## motif ti-idf data frame
df_insulin_mtor <- c(id, insulin_dy, cl_mtor) ## motif ti-idf data frame
df_both_akt <-  c(id, motif_ti, insulin_dy, cl_akt)
df_both_mtor <-  c(id, motif_ti, insulin_dy, cl_mtor)

get_negtive <- function(df, cols, classname, nrecord = 110) {
# classname <- quo_name(enquo(classname))
pos <- model_df(df, cols) %>% rename(class = !!classname) %>% filter(class == 1)
pos.1 <- pos %>% mutate(pred = 1)

# df_list <- list()

df_list <- model_df(df, cols)  %>% rename(class = !!classname) %>% mutate(pred = 0)

df_score <- df_list %>% select(1)

e <- k <- 1 # initiate loop

while (k < 6) {
  df_prepared <- data.frame()
  df_d <- df_list %>% filter(class != 1, pred == 0) %>% select(-pred) %>% 
    sample_n(dim(.)[1]) %>% 
    mutate(group = ntile(row_number(), floor(dim(.)[1] / nrecord)))

  groups <- max(df_d$group)
  print(groups)

  k_df.1 <- df_list %>% filter(class != 1, pred == 0) %>% select(1, pred)
  
  for (i in seq(1:groups)){
    df_neg <- df_d %>% filter(group == i) %>% select(-group)
    
    df_train <- bind_rows(pos, df_neg)
    
    df_train.fit <- FFTrees(formula = class ~ .,
                             data = df_train[,-1],
                             sens.w = 1,
                             goal = "wacc",
                             do.comp = FALSE,
                             decision.labels = c("Not Akt", "Akt"),
                             main = paste0("The ", k, ifelse(k == 1, "st", ifelse(k == 2, "nd", "rd")), " Round No. ", i, " Subgroup")
    )
    # plot(df_train.fit)
    df_pred <- predict(df_train.fit, data = df_train)
    df_pred.1 <- bind_cols(df_train, pred = as.integer(df_pred)) %>% filter(class != 1)
    
    df_prepared <- bind_rows(df_prepared, df_pred.1)
    print(paste(k, "round", i, "subgroup"))
  }
  k <- k + 1
  df_score <- bind_rows(df_prepared, pos.1) %>% select(1, pred) %>%
    inner_join(df_score, by = c("identifier" = "identifier"))
  
  print(k)
  # if (k > 5)
  #   break
}
print(k)
return(df_score)
}
###############################################################
###############################################################
# dont run this code this it takes long time
# return_list <- get_negtive(ins_df, df_both_akt, "is_akt", 33)
# write_csv(return_list, "akt_negtive_both.csv")
# 
# return_list <- get_negtive(ins_df, df_both_mtor, "is_mtor", 33)
# write_csv(return_list, "mtor_negtive_both.csv")

## load preclassifiered negtive sites
akt_negtive <- read_csv("akt_negtive_both.csv") %>% 
  mutate(akt_neg_prob = 1 - rowMeans(.[2:6])) %>% 
  select(identifier, akt_neg_prob)

mtor_negtive <- read_csv("mtor_negtive_both.csv") %>% 
  mutate(mtor_neg_prob = 1 - rowMeans(.[2:6])) %>% 
  select(identifier, mtor_neg_prob)

df_negtives <- inner_join(akt_negtive, mtor_negtive)
ins_df_with_neg <- ins_df %>% inner_join(df_negtives, by = c("identifier" = "identifier"))


# write_csv(ins_df_with_neg, "ins_df_with_neg_new.csv")

# ins_df_with_neg <- read_csv("ins_df_with_neg_new.csv")

```

## 4. Use t-SNE to Visualize the Known Akt and mTor Sites

``` {r tsne, message=FALSE, warning=FALSE}
## prepare data for TSNE demension reduction
ins_ts_all <- ins_df_with_neg %>% mutate(class = is_akt + ifelse(is_mtor == 1, 2, 0)) %>% 
  mutate(is_mtor = ifelse(is_mtor == 1, 2, 0), akt_neg_prob = ifelse(akt_neg_prob == 1, 4, 0),
         mtor_neg_prob = ifelse(mtor_neg_prob == 1, 8, 0)) %>% 
  mutate (class = is_akt + is_mtor + akt_neg_prob + mtor_neg_prob) %>% 
  select(id, motif_ti, class) %>% 
  group_by(ti_pos01, ti_pos02, ti_pos03, ti_pos04, ti_pos05, ti_pos06, ti_pos07, 
           ti_pos08, ti_pos09, ti_pos10, ti_pos11, ti_pos12, ti_pos13, ti_skip1_pos01, 
           ti_skip1_pos02, ti_skip1_pos03, ti_skip1_pos04, ti_skip1_pos05, 
           ti_skip1_pos06, ti_skip1_pos07, ti_skip1_pos08, ti_skip1_pos09, 
           ti_skip1_pos10, ti_skip1_pos11, ti_2gram_pos01, ti_2gram_pos02, 
           ti_2gram_pos03, ti_2gram_pos04, ti_2gram_pos05, ti_2gram_pos06, 
           ti_2gram_pos07, ti_2gram_pos08, ti_2gram_pos09, ti_2gram_pos10, 
           ti_2gram_pos11, ti_2gram_pos12) %>% 
  mutate(rnum = row_number()) %>% 
  ungroup()

# deduplicate data for tsne
ins_ts <-  ins_ts_all %>% filter(rnum == 1)

df_for <- ins_ts[, c(motif_ti)]
df_unique <- unique(df_for) # this istep is not neccesory as it is already unique

#######the below code take about 3 minutes to run , commented out
# tene_out <- Rtsne(as.matrix(df_unique), check_duplicates = F)
# df_out <- as.data.frame(tene_out$Y)
# write_csv(df_out, "tsne_df_out.csv")
df_out <- read_csv("tsne_df_out.csv")

## USE DBSCAN TO CLUSTERING THE tsne output
cl <- hdbscan(df_out, minPts = 10)
df_out <- df_out %>% bind_cols(data.frame(dbcl = cl$cluster, clprob = cl$membership_prob))

ins_ts_with_cluster <- ins_ts %>% bind_cols(data.frame(dbcluster = cl$cluster, 
                                                       cluster_prob = cl$membership_prob)) %>% 
  select(motif_ti, dbcluster, cluster_prob)

# str(ins_ts_with_cluster)
id_with_cluster <- ins_df_with_neg %>% inner_join(ins_ts_with_cluster)
# write_csv(id_with_cluster, "processed_data_with_motif_negtive_cluster_new.csv")


tsne_df <- bind_cols(df_out, ins_ts[, "class"]) %>%
  mutate(dbcl = factor(dbcl), class = factor(class))

tsne_df.akt <- filter(tsne_df, class == 1)
tsne_df.mtor <- filter(tsne_df, class == 2)
tsne_df.neg <- filter(tsne_df, class == 4)

## plot plain tsne out put
g1 <- ggplot(tsne_df, aes(x=V1, y=V2)) +
  geom_point(size = 0.25) +
  guides(colour=guide_legend(override.aes=list(size=4))) +
  xlab("") + ylab("") +
  ggtitle("Motif t-SNE 2 Dimentions") +
  theme_light(base_size=20) +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        plot.title = element_text(hjust = 0.5, size = 16),
        legend.title = element_text(color = "black", size = 12),
        legend.text = element_text(color = "black", size = 10)
  )
g1

## plot plain tsne output with Akt known
g2 <- ggplot(tsne_df, aes(x=V1, y=V2)) +  
  geom_point(size = 0.25) +
  geom_point(data = tsne_df.akt, aes(x=V1, y=V2, fill = class), col = "black", size = 4, shape = 23) +
  # geom_point(data = tsne_df.mtor, aes(x=V1, y=V2, fill = class), col = "black", size = 4, shape = 23) +
  # geom_point(data = tsne_df.neg, fill = "yellow", size = 1, shape = 24) +
  guides(colour=guide_legend(override.aes=list(size=4))) +
  # scale_colour_brewer(palette = "Set2") +
  scale_fill_manual("Substrate", values = c("red", "magenta"), labels = c("Akt", "mTor")) +
  # scale_color_manual("DB Cluster", values = c("#669999", "#248f24", "#0000ff", "#e6e600")) +
  xlab("") + ylab("") +
  ggtitle("Motif t-SNE 2 Dimentions overlay with Known Akt") +
  theme_light(base_size=20) +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        plot.title = element_text(hjust = 0.5, size = 16),
        legend.title = element_text(color = "black", size = 12),
        legend.text = element_text(color = "black", size = 10)
  )
g2

## plot plain tsne output with mTor known
g3 <- ggplot(tsne_df, aes(x=V1, y=V2)) +  
  geom_point(size = 0.25) +
  geom_point(data = tsne_df.akt, aes(x=V1, y=V2, fill = class), col = "black", size = 4, shape = 23) +
  geom_point(data = tsne_df.mtor, aes(x=V1, y=V2, fill = class), col = "black", size = 4, shape = 23) +
  # geom_point(data = tsne_df.neg, fill = "yellow", size = 1, shape = 24) +
  guides(colour=guide_legend(override.aes=list(size=4))) +
  # scale_colour_brewer(palette = "Set2") +
  scale_fill_manual("Substrate", values = c("red", "magenta"), labels = c("Akt", "mTor")) +
  # scale_color_manual("DB Cluster", values = c("#669999", "#248f24", "#0000ff", "#e6e600")) +
  xlab("") + ylab("") +
  ggtitle("Motif t-SNE 2 Dimentions overlay with Known Akt & mTor") +
  theme_light(base_size=20) +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        plot.title = element_text(hjust = 0.5, size = 16),
        legend.title = element_text(color = "black", size = 12),
        legend.text = element_text(color = "black", size = 10)
  )
g3

## with dbscan cluster
g4 <- ggplot(tsne_df, aes(x=V1, y=V2, col = dbcl)) +  
  geom_point(size = 0.25) +
  geom_point(data = tsne_df.akt, aes(x=V1, y=V2, fill = class), col = "black", size = 4, shape = 23) +
  geom_point(data = tsne_df.mtor, aes(x=V1, y=V2, fill = class), col = "black", size = 4, shape = 23) +
  # geom_point(data = tsne_df.neg, fill = "yellow", size = 1, shape = 24) +
  guides(colour=guide_legend(override.aes=list(size=4))) +
  # scale_colour_brewer(palette = "Set2") +
  scale_fill_manual("Substrate", values = c("red", "magenta"), labels = c("Akt", "mTor")) +
  scale_color_manual("DB Cluster", values = c("#669999", "#248f24", "magenta", "darkblue", "#e6e600", "#0000ff")) +
  xlab("") + ylab("") +
  ggtitle("Motif t-SNE 2 Dimentions overlay with Known Akt & mTor\n+ DBSCAN Cluster") +
  theme_light(base_size=20) +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        plot.title = element_text(hjust = 0.5, size = 16),
        legend.title = element_text(color = "black", size = 12),
        legend.text = element_text(color = "black", size = 10)
        )
g4

```

## 5. Feature Correlation Study
``` {r features, message=FALSE, warning=FALSE}
## load more packages
library(plyr)
library(dplyr) ## this should load one after another as this seq
library(xgboost)
library(caret)
library(recipes)


## inmport data from above output
id_with_cluster <- read_csv("processed_data_with_motif_negtive_cluster_new.csv") %>% 
  dplyr::mutate(dbcluster = ifelse(dbcluster %in% c(3, 5), 9, dbcluster))


## get vars
vars <- names(id_with_cluster)
id <- vars_select(vars, identifier) # id field
motif_ch <- vars_select(vars, starts_with("pos")) # motif symbol columns
motif_ti <- vars_select(vars, starts_with("ti_"), -ti_pos07) # motif ti-idf fields of motif symbol
insulin_dy <- vars_select(vars, starts_with("p_")) # fields for insuline fold change values
both_var <- vars_select(vars, motif_ti, insulin_dy)
cl_akt <- vars_select(vars, is_akt)
cl_mtor <- vars_select(vars, is_mtor)
train_other <- vars_select(vars, is_akt, is_mtor, akt_neg_prob, mtor_neg_prob, dbcluster)

vars_for_akt <- setdiff(vars, c(motif_ch, cl_mtor))
vars_for_akt.m <- setdiff(vars_for_akt, c(id, cl_akt))
vars_for_mtor <- setdiff(vars, c(motif_ch, cl_akt))

###############################################################################
##correlation plot
library(corrplot)
library(gplots)

plot_cor <- function(target, threshold = 0.05){
  # cor_df <- select(id_with_cluster, vars_for_akt) %>% select(-identifier, -dbcluster, -cluster_prob)

  cor_df <- select(id_with_cluster, motif_ti, insulin_dy, is_akt,
                   is_mtor, akt_neg_prob, mtor_neg_prob)

  pair <- cor(cor_df)

  rws <- abs(pair[, target]) >= threshold
  ## filter out the only variables with higher coeeficiency
  xx <-  rownames(pair[rws,])
  # put the desired variables in first column
  xx <- xx[which(!is.na(xx))]
  xx <- c(target, setdiff(xx, target))

  yy <- pair[xx, xx]
  order <- order(abs(yy[,1]), decreasing = T)

  yy.1 <- yy[order(abs(yy[,1]),decreasing = T),]
  rw.init <- rownames(yy.1)
  # rw
  cor_tidy <- cor(cor_df[, rw.init])
  # correlation plot
  corrplot.mixed(corr = cor_tidy,
                 upper = "ellipse", tl.pos = "lt",
                 color = colorpanel(50, "red", "gray60", "blue4")
  )

}

```

### 5.1 Akt Sites and Its Correlated Features
``` {r aktcor, message=FALSE, warning=FALSE}
## plot the valiables correlate to is_akt
plot_cor("is_akt", threshold = 0.07)
```

From the correlation matrix, we can see that the the Akt is more reacted to the short time phosphoproteomic data. And we can also notice that many variables are correlated each other. This suggests that we will need to perform the feature reduction process.

### 5.2 mTor Sites and Its Correlated Features
``` {r mtorcor, message=FALSE, warning=FALSE}
## plot the valiables correlate to is_mtor
plot_cor("is_mtor")
```

From the correlation matrix, we can see that the the mTor is more reacted to the longer time phosphoproteomic data. And we can also notice that many variables are correlated each other. This suggests that we will need to perform the feature reduction process.

##6. Build the model
We tried 3 different approaches

###6.1. Positive unlabeled learning via wrapper-based adaptive sampling
```{r, message= FALSE, warning=FALSE}
library(e1071)
library(randomForest)

Adaptive.Sampling <- function(X,Y, err = 0.01, max.sampling = 10000, n.tree = 1000, percentage.features = 1.0) {
  # split data between labeled and unlabeled for specific kinase
  labeled.index <- which(!is.na(Y))
  labeled.data <- X[labeled.index[which(Y[labeled.index] == 1)],]
  unlabeled.index <- which(is.na(Y))
  unlabeled.data <- X[unlabeled.index,]
  # set initial probability weight to 1
  unlabeled.data$weight <- 1
  # set the labeled phosphorylation sites to 1 and the unlabeled to 0
  y.train <- as.factor(c(rep(1,nrow(labeled.data)), rep(0,nrow(labeled.data))))
  
  prev.prob = 1
  min.x.train <- NA
  min.score <- 1
  ctr <- 0
  repeat {
    ctr <- ctr + 1
    # sample unlabeled data
    sample.unlabeled.index <- sample(1:nrow(unlabeled.data), nrow(labeled.data), TRUE, unlabeled.data$weight)
    # concat labeled and unlabeled data to construct training set
    x.train <- rbind(labeled.data, unlabeled.data[sample.unlabeled.index,-ncol(unlabeled.data)])
    # fit to model
    svm_radial <- svm(x.train, y.train, type="C-classification", kernel = "radial", scale = FALSE, probability = TRUE)
    svm_radial_pred <- predict(svm_radial, X, probability=TRUE) 
    # get probability of label = 1
    prob.pred <- attr(svm_radial_pred, "probabilities")[,'1']
    # update the probability weight of negative labeled data
    #unlabeled.data$weight <- pmin(unlabeled.data$weight, 1 - prob.pred[unlabeled.index])
    # for prediction probability of positive class above 0.9, set the weight to 0
    #unlabeled.data$weight[which(unlabeled.data$weight < 0.1)] = 0
    
    # calculate the score and store the minimum training set
    score <- mean(abs(prob.pred - prev.prob))
    if (score < min.score) {
      min.score <- score
      min.x.train <- x.train
    }
    
    prev.prob <- prob.pred
    # exit the loop if reaching max iteration or score is lower than threshold
    if (score < err || ctr  >= max.sampling) {
      break
    }
  }
  
  #cat(ctr, min.score,"\n")
  # build ensemble model with different feature size
  rf <- randomForest(min.x.train, y.train, xtest=X, mtry=round(percentage.features*ncol(X)), importance=TRUE, ntree=n.tree)
  #print(rf$importance)
  rf$test$votes[,'1']
  #rf$test$predicted
}

#Normalize the data and apply PCA, call adaptive sampling
preprocess.fit.predict.evaluate <- function(X,Y,threshold = 0.95,err = 0.01, max.sampling = 10000, n.tree = 1000, percentage.features = 1.0) {
  pca <- preProcess(X,method=c("BoxCox", "center", "scale", "pca"), thresh = threshold)
  pred.prob <- Adaptive.Sampling(predict(pca,X),Y,err = err, max.sampling = max.sampling, n.tree = n.tree, percentage.features = percentage.features)
  pred.prob
}

# find the best parameters
exclude_columns <- c(1:14,21,69:74)
new_features <- id_with_cluster[,-exclude_columns]

if (file.exists("AdaSampling_prob_result.csv")) {
  prob.result <- read.csv("AdaSampling_prob_result.csv")
} else {
  for (vari in c(0.7,0.8,0.9,0.95)) {
    for (ft in c(0.6,0.7,0.8,0.9,1)) {
      labels[paste("Akt", vari,ft, sep = "_")] <- preprocess.fit.predict.evaluate(new_features,labels$Akt,vari, percentage.features = ft)
      labels[paste("mTOR", vari,ft, sep = "_")] <- preprocess.fit.predict.evaluate(new_features,labels$mTOR,vari, percentage.features = ft)
    }
  }
  prob.result <- cbind(dt[,1], labels)
  colnames(prob.result)[1] <- "Identifier"
  #save to file
  #write.csv(prob.result, "prob_result.csv", row.names = FALSE)
}

# Calculate the prediction scores
data.2016.akt <- read.csv("2016 result (Akt).csv")
data.2016.mtor <- read.csv("2016 result (mTOR).csv")

evaluation <- function(data.2016,result_from_model,threshold = 0.5) {
  data.2016$modelResult <- with(result_from_model,
                                result_from_model$avg.prob[match(data.2016$Name,                                                             result_from_model$identifier)])

  if (class(data.2016$modelResult) == "factor") {
    data.2016$modelResult <- as.numeric(levels(data.2016$modelResult))[data.2016$modelResult]
  }
  truth <- ifelse(data.2016$Full.model.predict>threshold,1,0)
  result <- ifelse(data.2016$modelResult>threshold,1,0)
  
  TP <- c(sum((truth == result)[truth == 1]))
  TN <- c(sum((truth == result)[truth == 0]))
  FP <-  c(sum((truth != result)[truth == 0]))
  FN <-  c(sum((truth != result)[truth == 1]))
  
  acc <- (TN+TP)/(TN+TP+FP+FN)*100
  spec <- TN/(TN+FP)*100
  sens <- TP/(TP+FN)*100
  f1 <- 2*TP/(2*TP+FP+FN)*100
  geo <- sqrt((TP/(TP+FN))*(TP/(TP+FP)))*100
  
  cat("accuracy =", round(acc,2),", ")
  cat("sensitivity =",round(sens,2),", specificity =",round(spec,2),", ")
  cat("f1 =" ,round(f1,2) , ", geo-mean =",round(geo,2),"\n")
  c(acc,sens,spec,f1,geo)
}

scores = matrix(nrow = ncol(prob.result)-3,ncol = 6)
i <- 1
max.akt.score <- 0
max.mtor.score <- 0
best.akt <- ""
best.mtor <- ""
for (col in colnames(prob.result[,4:ncol(prob.result)])) {
  model.result <- data.frame(cbind(as.character(prob.result$Identifier), prob.result[[col]]))
  colnames(model.result) <- c("identifier", "avg.prob")
  
  if (substr(col,1,3) == "Akt") {
    temp <- evaluation(data.2016.akt,model.result,0.5)
    scores[i,] <- c(col,temp)
    
    if (temp[2] > max.akt.score) {
      max.akt.score <- temp[2]
      best.akt <- col
    }
  } else {
    temp <- evaluation(data.2016.mtor,model.result,0.5)
    scores[i,] <- c(col,temp)
    if (temp[2] > max.mtor.score) {
      max.mtor.score <- temp[2]
      best.mtor <- col
    }
  }
  
  i <- i + 1
}

cat("Best Akt model", best.akt, "sensitivity:", max.akt.score)
cat("Best mTOR model", best.mtor, "sensitivity:", max.mtor.score)

colnames(scores) <- c("ID","Accuracy","Sensitivity","Specificity","F1-score", "Geo-mean")

# save to file
#write.csv(scores, "AdaSampling_scores_result.csv", row.names = FALSE)
write.table(id_with_cluster$identifier[which(prob.result[best.akt] > 0.5)], "AdaSampling_Akt_pred.csv", row.names = FALSE, col.names=FALSE)
write.table(id_with_cluster$identifier[which(prob.result[best.mtor] > 0.5)], "AdaSampling_mTOR_pred.csv", row.names = FALSE, col.names=FALSE)

```

###6.2. Positive-unlabeled ensemble learning with correction factor
```{r, message=FALSE,warning=FALSE}

#standardize numeric variables
standardize <- function(mat) {
 means <- apply(mat, 1, mean)
 stds <- apply(mat, 1, sd)
 tmp <- sweep(mat, 1, means, FUN="-")
 mat.stand <- sweep(tmp, 1, stds, FUN="/")
 return(mat.stand)
 }
data.scaled <- standardize(id_with_cluster[,-c(1:14,21,69:72)])

#PCA
data.pca <- prcomp(data.scaled,
                 center = TRUE,
                 scale. = TRUE) 
std = data.pca$sdev
var <- std^2
var_exp = var/sum(var)
plot(cumsum(var_exp), xlab = "Principal Component",
              ylab = "Cumulative Proportion of Variance Explained",
              type = "b")

#Choose the first 19 PC
sum(var_exp[1:19])
#0.9994939

#trainning dataset
data.after.pca = data.frame(is_akt=id_with_cluster$is_akt, akt_neg_prob=id_with_cluster$akt_neg_prob, 
                            is_mtor=id_with_cluster$is_mtor, mtor_neg_prob =id_with_cluster$mtor_neg_prob,
                            data.pca$x)
data.after.pca = data.after.pca[,1:23]

akt.pos = data.after.pca[data.after.pca["is_akt"]==1,-c(3,4)]
akt.neg = data.after.pca[data.after.pca["akt_neg_prob"]==1,-c(3,4)]
mtor.pos = data.after.pca[data.after.pca["is_mtor"]==1,-c(1,2)]
mtor.neg = data.after.pca[data.after.pca["mtor_neg_prob"]==1,-c(1,2)]

#testing dataset
data.test = data.after.pca[,-c(1:4)]

train_and_cf = function(selected_kernel,polyDegree,posData,negData){
  #initialise result matrix and correction factor list
  result.matrix = matrix(0, 12062, 200)
  cf = c()
  
  #train 200 base classifiers (SVM)
  for (i in 1:200){ 
    pos.train = posData
    neg.train = negData[sample(1:dim(negData)[1], 22, replace=TRUE),] #randomly select unlabled samples with replacement
    train = rbind(pos.train,neg.train)
    
    #split sampled data to training (2/3) and testing set (1/3)
    inTrain <- createDataPartition(train[,1], p = 2/3)[[1]]
    train.train = train[inTrain,]
    train.test = train[-inTrain,]
  
    #train SVM model with polynomial kernel
    svm.model <- svm(train.train[,-c(1:2)], y=train.train[,1],kernel=selected_kernel,
                         degree=polyDegree, type="C-classification", 
                         scale = FALSE,probability = TRUE)
    #get prediction probability of the test set
    predTest <- predict(svm.model, train.test[,-c(1:2)], probability=TRUE)
  
    #calculate correction factors
    pos_idx = which(train.test[,1] == 1)
    cf = c(cf,mean(attr(predTest, "prob")[,"1"][pos_idx]))
    
    #predict with the base classifier
    pred <- predict(svm.model, data.test, probability=TRUE)
    
    #save result to matrix
    result.matrix[,i] = attr(pred, "prob")[,"1"]
  }
  
  #apply correction factor
  avg_prob_after_correction = result.matrix %*% (1/cf)/200
  
  return(cbind(id_with_cluster[1], avg.prob = avg_prob_after_correction))
}

#load the 2016 result of the phosphorylation sites in our dataset
data.2016.akt <- read.csv("2016 result (Akt).csv", sep = ",")
data.2016.mtor <- read.csv("2016 result (mTOR).csv", sep = ",")

#evaluation - akt
akt.result = train_and_cf("polynomial",2,akt.pos,akt.neg)
evaluation(data.2016.akt,akt.result, 0.5)

#evaluation - mTOR
mtor.result = train_and_cf("polynomial",2,mtor.pos,mtor.neg)
evaluation(data.2016.mtor,mtor.result, 0.5)

# save to file
write.table(akt.result$identifier[which(akt.result$avg.prob > 0.5)], "CorrFactor_Akt_pred.csv", row.names = FALSE, col.names=FALSE)
write.table(mtor.result$identifier[which(mtor.result$avg.prob > 0.5)], "CorrFactor_mTOR_pred.csv", row.names = FALSE, col.names=FALSE)
```


### 6.3. Build Ensemble Model with XGBoost Algorithm
``` {r ensembletrain, message=FALSE, warning=FALSE}
## set number if iteration for the ensemble training
groups <-  100

#######################################################################################
##train ensemble function
train_ensemble <- function(df, cols, classname) {
  # classname <- quo_name(enquo(classname))
  site <- ifelse(grepl("akt", classname), "akt_neg_prob",
                 ifelse(grepl("mtor", classname), "mtor_neg_prob", classname))
  cn <- ifelse(grepl("akt", classname), 4,
         ifelse(grepl("mtor", classname), 9, 0))
  ## removed
  pos <- model_df(df, cols) %>% dplyr::rename(class = !!classname, site_neg_prob = !!site) %>% filter(class == 1) %>%
    select(-site_neg_prob)
  # pos.1 <- pos %>% mutate(pred = 1)

  nrecord <- dim(pos)[1]
  # print(site)
  # removed , site_neg_prob = !!site
  df_data <- model_df(df, cols)  %>% dplyr::rename(class = !!classname, site_neg_prob = !!site)

  df_list <- df_data %>% filter(site_neg_prob == 1, dbcluster != cn) # %>% mutate(pred = 0)
  # df_test <- df_data %>% filter(class != 1) %>% select(-site_neg_prob)

  df_d <- df_list %>% sample_n(dim(.)[1]) %>%
      dplyr::mutate(group = ntile(row_number(), ceiling(dim(.)[1] / nrecord))) %>% select(-site_neg_prob)

#####Initialize the return lists, and dataframes
  df_model <- list()
  best_param <- list()
  df_predict <- data.frame()
  feature_imp <- data.frame()
  df_score <-  list()

  for (i in seq(1:groups)){
      df_neg <- df_d %>% filter(group == i) %>% select(-group)
      # index <- sample(1:44, ceiling(88/3))
      df_train <- bind_rows(pos, df_neg)
      df_train.d <- select(df_train, -identifier, -class) %>% data.matrix(.)
      df_train.l <- factor(df_train$class, labels = c("neg", "pos"))

      ##########################################
      ######below code is commented as it has long time to run and we have got the best
      ## variables
      ## xgb hyperparameter grid search
      # xgb.grid <- expand.grid(
      #   nrounds = 10,
      #   max_depth = c(3, 4),
      #   eta = c(0.05, 0.1, 0.2, 0.4),  #c(0.001, 0.01, 0.05, 0.2)
      #   gamma = 0,
      #   colsample_bytree = c(0.4, 0.6, 0.8),  # c(0.4, 0.6, 0.8),
      #   min_child_weight = 1,
      #   subsample = c(0.3, 0.5, 0.8)
      # )

      xgb.grid <- expand.grid(
        nrounds = 10,
        max_depth = 3,
        eta = 0.5,  #c(0.001, 0.01, 0.05, 0.2) more generalize for mtor was 0.02 akt 759
        gamma = 0,
        colsample_bytree = 0.3,  # c(0.4, 0.6, 0.8), akt 759 0.5
        min_child_weight = 1,
        subsample = 0.5  # was 0.6
      )

      xgb.control <- trainControl(
        method = "repeatedcv",
        number = 3,
        repeats = 3,
        classProbs = TRUE,
        summaryFunction = twoClassSummary
      )

      df_model[[i]] <- train(
        x = df_train.d,
        y = df_train.l,
        trControl = xgb.control,
        tuneGrid = xgb.grid,
        metric = "AUC",
        objective = "binary:logistic",
        method = "xgbTree"
      )

      set.seed(i)
      best_param[[i]] <- as.list(df_model[[i]]$bestTune)
      df_train.l <- data.matrix(df_train$class)
      df_train.fit <- xgboost(data = df_train.d,
                              label = df_train.l,
                              nrounds = 10,
                              params = best_param[[i]],
                              objective = "binary:logistic"
                            )

      f_value <- data.frame(xgb.importance(dimnames(df_train.d)[[2]], df_train.fit)) %>% select(Feature, Gain)
      feature_imp <- bind_rows(feature_imp, f_value)
    }
 ensemble_out <- list()
 ensemble_out$best_param <- best_param
 ensemble_out$model <- df_model
 ensemble_out$features <- feature_imp
 # ensemble_out$score <- df_score
 return(ensemble_out)

}

## build the ensemble model for akt without feature engineering
# model_akt <- train_ensemble(id_with_cluster, vars_for_akt, "is_akt")
# saveRDS(model_akt, "model/model_akt.rds")
model_akt <- readRDS("model/model_akt.rds")

feature_importance_akt <- model_akt$features %>% 
  dplyr::group_by(Feature) %>% dplyr::summarise(Gain = mean(Gain)) %>% dplyr::arrange(desc(Gain)) %>% 
  dplyr::filter(Gain > 0.025)

ggplot(feature_importance_akt, aes(x = Gain, y = reorder(Feature, Gain))) +
  geom_point(size = 4, color = "red") +
  geom_segment(aes(yend = Feature), xend = -Inf, color = "gray50") +
  labs(title = "Variable Improtance for Akt Prediction", y = "Variables") +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5, size = 14, color = "darkblue"),
        axis.text = element_text(size = 11, color = "blue"),
        axis.title = element_text(size = 12, color = "darkblue"))

## build the ensemble model for mtor with feature engineering
# model_mtor <- train_ensemble(id_with_cluster, vars_for_mtor, "is_mtor")
# saveRDS(model_mtor, "model/model_mtor.rds")
model_mtor <- readRDS("model/model_mtor.rds")

feature_importance_mtor <- model_mtor$features %>% 
  dplyr::group_by(Feature) %>% dplyr::summarise(Gain = mean(Gain)) %>% dplyr::arrange(desc(Gain)) %>% 
  dplyr::filter(Gain > 0.025)

ggplot(feature_importance_mtor, aes(x = Gain, y = reorder(Feature, Gain))) +
  geom_point(size = 4, color = "red") +
  geom_segment(aes(yend = Feature), xend = -Inf, color = "gray50") +
  labs(title = "Variable Improtance for mTor Prediction", y = "Variables") +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5, size = 14, color = "darkblue"),
        axis.text = element_text(size = 11, color = "blue"),
        axis.title = element_text(size = 12, color = "darkblue"))

```

## 7. Feature Selection by PCA
``` {r pca, message=FALSE, warning=FALSE}
## preprocess data and features selection with recipes

pre_baking <- function(df, columns, threshold = 0.95) {
  rec <- recipe(~., data = df)
  prep_train <- rec %>% 
    # step_center(motif_ti, insulin_dy) %>%
    step_scale(columns) %>% 
    step_pca(columns, threshold = threshold)
  prep_train <- prep(prep_train, training = df)
  df_baked <- bake(prep_train, newdata = df)
  var.pca <- names(df_baked)
  
  pca_vars <- vars_select(var.pca, starts_with("PC"))
  var_pca_akt <- vars_select(var.pca, id, pca_vars, train_other, -is_mtor)
  var_pca_mtor <- vars_select(var.pca, id, pca_vars, train_other, -is_akt)
  baked <- list()
  baked$df <- df_baked
  baked$akt_var <- var_pca_akt
  baked$mtor_var <- var_pca_mtor
  return(baked)
}

## frist we use preprocessing for both variables and train the model
bake_df <- pre_baking(id_with_cluster, both_var)
################################################################################
###################################################################################
## below code are commented and it can be read from the saved model
# ## build model from dimesion reduced by pca for akt
# model_akt_pca <- train_ensemble(bake_df$df, bake_df$akt_var, "is_akt")
# saveRDS(model_akt_pca, "model/model_akt_pca.rds")
# ## build model from dimesion reduced by pca for mtor
# model_mtor_pca <- train_ensemble(bake_df$df, bake_df$mtor_var, "is_mtor")
# saveRDS(model_mtor_pca, "model/model_mtor_pca.rds")
# 
# ## second we use preprocessing for motif variables only and train the model
# bake_df_motif <- pre_baking(id_with_cluster, motif_ti)
# ## build model from dimesion reduced by pca for akt with motif variables only
# model_akt_pca_motif <- train_ensemble(bake_df_motif$df, bake_df_motif$akt_var, "is_akt")
# saveRDS(model_akt_pca_motif, "model/model_akt_pca_motif.rds")
# 
# ## build model from dimesion reduced by pca for mtor with motif variables only
# model_mtor_pca_motif <- train_ensemble(bake_df_motif$df, bake_df_motif$mtor_var, "is_mtor")
# saveRDS(model_mtor_pca_motif, "model/model_mtor_pca_motif.rds")
# 
# ## secon we use preprocessing for phosphoproteomic variables only and train the model
# bake_df_insulin <- pre_baking(id_with_cluster, insulin_dy)
# 
# ## build model from dimesion reduced by pca for akt with phosphoproteomic variables only
# model_akt_pca_insulin <- train_ensemble(bake_df_insulin$df, bake_df_insulin$akt_var, "is_akt")
# saveRDS(model_akt_pca_insulin, "model/model_akt_pca_insulin.rds")
# 
# ## build model from dimesionreducted by pca for mtor
# model_mtor_pca_insulin <- train_ensemble(bake_df_insulin$df, bake_df_insulin$mtor_var, "is_mtor")
# saveRDS(model_mtor_pca_insulin, "model/model_mtor_pca_insulin.rds")

```

## 8. Model Training With PCA Dimension Reduction
``` {r train_pca, message=FALSE, warning=FALSE}
################################################################################
###################################################################################
## below code are commented and it can be read from the saved model
# ## build model from dimesion reducted by pca for akt
# model_akt_pca <- train_ensemble(bake_df$df, bake_df$akt_var, "is_akt")
# saveRDS(model_akt_pca, "model/model_akt_pca.rds")
# ## build model from dimesion reducted by pca for mtor
# model_mtor_pca <- train_ensemble(bake_df$df, bake_df$mtor_var, "is_mtor")
# saveRDS(model_mtor_pca, "model/model_mtor_pca.rds")
# 
# ## second we use preprocessing for motif variables only and train the model
# bake_df_motif <- pre_baking(id_with_cluster, motif_ti)
# ## build model from dimesionreducted by pca for akt with motif variables only
# model_akt_pca_motif <- train_ensemble(bake_df_motif$df, bake_df_motif$akt_var, "is_akt")
# saveRDS(model_akt_pca_motif, "model/model_akt_pca_motif.rds")
# 
# ## build model from dimesionreducted by pca for mtor with motif variables only
# model_mtor_pca_motif <- train_ensemble(bake_df_motif$df, bake_df_motif$mtor_var, "is_mtor")
# saveRDS(model_mtor_pca_motif, "model/model_mtor_pca_motif.rds")
# 
# ## secon we use preprocessing for motif variables only and train the model
# bake_df_insulin <- pre_baking(id_with_cluster, insulin_dy)
# 
# ## build model from dimesionreducted by pca for akt with motif variables only
# model_akt_pca_insulin <- train_ensemble(bake_df_insulin$df, bake_df_insulin$akt_var, "is_akt")
# saveRDS(model_akt_pca_insulin, "model/model_akt_pca_insulin.rds")
# 
# ## build model from dimesionreducted by pca for mtor
# model_mtor_pca_insulin <- train_ensemble(bake_df_insulin$df, bake_df_insulin$mtor_var, "is_mtor")
# saveRDS(model_mtor_pca_insulin, "model/model_mtor_pca_insulin.rds")

```



## 9. Prediction 
``` {r pred, message=FALSE, warning=FALSE}

# prediction function
predict_ensemble <- function(df, cols, classname, model_list) {
  # classname <- quo_name(enquo(classname))
  site <- ifelse(grepl("akt", classname), "akt_neg_prob",
                 ifelse(grepl("mtor", classname), "mtor_neg_prob", classname))
  
  df_train <- model_df(df, cols)  %>% dplyr::rename(class = !!classname, site_neg_prob = !!site) %>% select(-site_neg_prob)
  df_train.d <- df_train %>% select(-identifier, -class) %>% data.matrix(.)
  
  df_pred_out <- df_train %>% select(identifier, class)
  #####Initialize the return lists, and dataframes
  df_model <- list()
  best_param <- list()
  df_predict <- data.frame()
  feature_imp <- data.frame()
  
  for (i in seq(1:groups)){
    # df_train.l <- factor(df_train$class, labels = c("neg", "pos"))
    
    df_pred <- predict(model_list$model[[i]], df_train.d, type = "prob")
    df_pred_out <- bind_cols(df_pred_out, pred = df_pred$pos)
    colnames(df_pred_out)[i + 2] <- paste0("pred_", i)
  }
  
  return(df_pred_out) 
  
}

##final result from the ensemble prediction

preodicted_result <- function(df, cols, classname, model_list) {
  predicted <- predict_ensemble(df, cols, classname, model_list)
  last_col <- dim(predicted)[2]
  predict_final <- predicted %>% mutate(avg_prob = rowMeans(.[3:last_col])) %>%
    select(identifier, class, avg_prob) %>% 
    mutate(avg_prob_scale = (avg_prob - range(.$avg_prob)[1]) /diff(range(.$avg_prob))) %>% 
    mutate(class_pred = avg_prob_scale > 0.5)
}
########################################################
########################################################
#################Below code are deliberated commented as 
## the result is already saved

# ## predict on the raw model without preprocessing
# akt <- preodicted_result(id_with_cluster, vars_for_akt, "is_akt", model_akt)
# mtor <- preodicted_result(id_with_cluster, vars_for_mtor, "is_mtor", model_mtor)
# 
# ## get predict result for preproceed on both data
# akt_pca <- preodicted_result(bake_df$df, bake_df$akt_var, "is_akt", model_akt_pca)
# mtor_pca <- preodicted_result(bake_df$df, bake_df$mtor_var, "is_mtor", model_mtor_pca)
# 
# ## get predict result for preproceed on motif data
# akt_pca_motif <- preodicted_result(bake_df_motif$df, bake_df_motif$akt_var, "is_akt", model_akt_pca_motif)
# mtor_pca_motif <- preodicted_result(bake_df_motif$df, bake_df_motif$mtor_var, "is_mtor", model_mtor_pca_motif)
# 
# ## get predict result for preproceed on insulin data
# akt_pca_insulin <- preodicted_result(bake_df_insulin$df, bake_df_insulin$akt_var, "is_akt", model_akt_pca_insulin)
# mtor_pca_insulin <- preodicted_result(bake_df_insulin$df, bake_df_insulin$mtor_var, "is_mtor", model_mtor_pca_insulin)

combine_pred <- function(base, df1, df2, df3) {
    base %>% select(identifier, motif) %>% 
    inner_join(df1, by =c("identifier"="identifier")) %>% 
    inner_join(df2, by =c("identifier"="identifier")) %>% 
    rename(Full_Prob = avg_prob_scale.x, 
           Motif_Prob = avg_prob_scale.y,
           result_full = class_pred.x,  result_motif = class_pred.y) %>% 
    select(-starts_with("class"), -starts_with("avg_")) %>% 
    inner_join(df3, by =c("identifier"="identifier")) %>% 
    rename(PP_Prob = avg_prob_scale, result_pp = class_pred) %>% 
    select(-starts_with("class"), -starts_with("avg_")) %>% 
    mutate(verdict = ifelse(result_full + result_motif + result_pp == 3, TRUE, FALSE))
}

# akt_prediction_results <- combine_pred(ins, akt_pca, akt_pca_motif, akt_pca_insulin)  ## 443 verdict
# write_csv(akt_prediction_results, "model/akt_prediction_results.csv")
# mtor_prediction_results <- combine_pred(ins, mtor_pca, mtor_pca_motif, mtor_pca_insulin) ## 1989 verdict
# write_csv(mtor_prediction_results, "model/mtor_prediction_results.csv")

akt_prediction_results <-  read_csv("model/akt_prediction_results.csv")
mtor_prediction_results <-  read_csv("model/mtor_prediction_results.csv")

```

## 10. Prediction Comparison with 2016 Prediction
``` {r comp, message=FALSE, warning=FALSE}

confu_plot <- function(Now, LY, title) {
  xx.1 <- as.matrix(table(Now, LY))
  dimnames(xx.1)[[1]] <- c("Pred FALSE", "Pred TRUE")
  dimnames(xx.1)[[2]] <- c("2016 FALSE", "2016 TRUE")
  fourfoldplot(t(xx.1), color = c("red", "#6699CC"),
               margin = 2,
               main = title)
}

```

### 10.1 Akt Prediction Comparison with 2016 Prediction
``` {r compakt, message=FALSE, warning=FALSE}
oldpar <- par(mfrow = c(2,2))
xx <- akt_prediction_2016 %>% inner_join(akt_prediction_results, by = c("identifier" = "identifier"))

confu_plot(xx$result_full, xx$akt_full, "Akt All Variables")
confu_plot(xx$result_motif, xx$akt_motif, "Akt Motif Only")
confu_plot(xx$result_pp, xx$akt_pp, "Akt Phosphoproteome")
confu_plot(xx$verdict, xx$akt_full, "Akt Predict Combined")

```

### 10.2 mTor Prediction Comparison with 2016 Prediction
``` {r compmtor, message=FALSE, warning=FALSE}

oldpar <- par(mfrow = c(2,2))
xx <- mtor_prediction_2016 %>% inner_join(mtor_prediction_results, by = c("identifier" = "identifier"))
confu_plot(xx$result_full, xx$mtor_full, "mTor All Variables")
confu_plot(xx$result_motif, xx$mtor_motif, "mTor Motif Only")
confu_plot(xx$result_pp, xx$mtor_pp, "mTor Phosphoproteome")
confu_plot(xx$verdict, xx$mtor_full, "mTor Predict Combined")
par(oldpar)

```

### 10.3 Overlapping for 2016 prediction between Akt and mTor
``` {r olakt, message=FALSE, warning=FALSE}
## akt and mtor overlapping
library(VennDiagram)

# create draw overlapping function
draw_overlap <- function(a1, a2, overlap, cat){
  # dev.off()
  venn.plot <- draw.pairwise.venn(a1, a2, overlap, category = cat, 
                                  ext.text = FALSE,
                                  label.col = rep("white", 3),
                                  cex = rep(2,3),
                                  fill = c("red", "#6699CC"),
                                  cat.pos = c(-25, 25), 
                                  cat.dist = rep(0.05, 2),
                                  alpha = rep(0.6, 2),
                                  cat.cex = rep(1, 2),
                                  cat.col = c("red", "#6699CC"),
                                  cat.fontface = rep("bold", 1),
                                  cat.fontfamily = rep("Arial", 2)
  )
  grid.draw(venn.plot);
}

## overlapping for 2016 prediction between Akt and mTor
a1 <- sum(akt_prediction_2016$akt_full)
a2 <- sum(mtor_prediction_2016$mtor_full)
overlap <- inner_join(akt_prediction_2016, mtor_prediction_2016, by = c("identifier" = "identifier")) %>% 
  filter(akt_full == mtor_full, mtor_full == TRUE) %>% nrow

grid.newpage();
draw_overlap(a1, a2, overlap, c("2016 Akt", "2016 mTor"))

```


### 10.4 Overlapping for new prediction between Akt and mTor
``` {r olmtor, message=FALSE, warning=FALSE}
# overlaping for new prediction between Akt and mTor
a1 <- sum(akt_prediction_results$verdict)
a2 <- sum(mtor_prediction_results$verdict)
overlap <- inner_join(akt_prediction_results, mtor_prediction_results, by = c("identifier" = "identifier")) %>% 
  filter(verdict.x == verdict.y, verdict.x == TRUE) %>% nrow
grid.newpage();
draw_overlap(a1, a2, overlap, c("Predict Akt", "Predict mTor"))
```

### 10.5 Overlapping XGBoost Predicted Akt with tSNE Result
``` {r outtsne, message=FALSE, warning=FALSE}

a.2 <- select(akt_prediction_results, identifier, Full_Prob, verdict) %>% 
  dplyr::mutate(verdict = as.integer(verdict))
a.3 <- select(mtor_prediction_results, identifier, Full_Prob, verdict) %>% 
  dplyr::mutate(verdict_m = as.integer(verdict)) %>% select(-verdict, -Full_Prob)

# overlaping for new prediction between Akt and mTor
df_out <- read_csv("tsne_df_out.csv")

ins_df_with_neg <- read_csv("ins_df_with_neg_new.csv")
ins_df_with_neg <- ins_df_with_neg %>% inner_join(a.2) %>% 
  inner_join(a.3)
ins_ts_all <- ins_df_with_neg %>% dplyr::mutate(class = verdict + ifelse(is_mtor == 1, 2, 0)) %>% 
  dplyr::mutate(is_mtor = ifelse(verdict_m == 1, 2, 0), akt_neg_prob = ifelse(akt_neg_prob == 1, 4, 0),
         mtor_neg_prob = ifelse(mtor_neg_prob == 1, 8, 0)) %>% 
  dplyr::mutate (class = verdict + is_mtor + akt_neg_prob + mtor_neg_prob) %>% 
  select(id, motif_ti, class) %>% 
  dplyr::group_by(ti_pos01, ti_pos02, ti_pos03, ti_pos04, ti_pos05, ti_pos06, 
           ti_pos08, ti_pos09, ti_pos10, ti_pos11, ti_pos12, ti_pos13, ti_skip1_pos01, 
           ti_skip1_pos02, ti_skip1_pos03, ti_skip1_pos04, ti_skip1_pos05, 
           ti_skip1_pos06, ti_skip1_pos07, ti_skip1_pos08, ti_skip1_pos09, 
           ti_skip1_pos10, ti_skip1_pos11, ti_2gram_pos01, ti_2gram_pos02, 
           ti_2gram_pos03, ti_2gram_pos04, ti_2gram_pos05, ti_2gram_pos06, 
           ti_2gram_pos07, ti_2gram_pos08, ti_2gram_pos09, ti_2gram_pos10, 
           ti_2gram_pos11, ti_2gram_pos12) %>% 
  dplyr::mutate(rnum = row_number()) %>% 
  ungroup()

# deduplicate data for tsne
ins_ts <-  ins_ts_all %>% dplyr::filter(rnum == 1)

## USE DBSCAN TO CLUSTERING THE tsne output
cl <- hdbscan(df_out, minPts = 10)
df_out <- df_out %>% bind_cols(data.frame(dbcl = cl$cluster, clprob = cl$membership_prob))

ins_ts_with_cluster <- ins_ts %>% bind_cols(data.frame(dbcluster = cl$cluster, 
                                                       cluster_prob = cl$membership_prob)) %>% 
  select(motif_ti, dbcluster, cluster_prob)

tsne_df <- bind_cols(df_out, ins_ts[, "class"]) %>%
  dplyr::mutate(dbcl = factor(dbcl), class = factor(class))

tsne_df.akt <- dplyr::filter(tsne_df, class == 1)
tsne_df.mtor <- dplyr::filter(tsne_df, class == 2)
tsne_df.neg <- dplyr::filter(tsne_df, class == 4)

## plot plain tsne output with Akt known
g2 <- ggplot(tsne_df, aes(x=V1, y=V2)) +  
  geom_point(size = 0.25) +
  geom_point(data = tsne_df.akt, aes(x=V1, y=V2, fill = class), col = "black", size = 2, shape = 23) +
  # geom_point(data = tsne_df.mtor, aes(x=V1, y=V2, fill = class), col = "black", size = 4, shape = 23) +
  # geom_point(data = tsne_df.neg, fill = "yellow", size = 1, shape = 24) +
  guides(colour=guide_legend(override.aes=list(size=4))) +
  # scale_colour_brewer(palette = "Set2") +
  scale_fill_manual("Substrate", values = c("red", "magenta"), labels = c("Akt", "mTor")) +
  # scale_color_manual("DB Cluster", values = c("#669999", "#248f24", "#0000ff", "#e6e600")) +
  xlab("") + ylab("") +
  ggtitle("t-SNE 2 Dimentions Reduction overlay with XGB Predicted Akt") +
  theme_light(base_size=20) +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        plot.title = element_text(hjust = 0.5, size = 16),
        legend.title = element_text(color = "black", size = 12),
        legend.text = element_text(color = "black", size = 10)
  )
g2

```

### 10.6 Overlapping XGBoost Predicted mTor with tSNE Result
``` {r outtsnemt, message=FALSE, warning=FALSE}
g3 <- ggplot(tsne_df, aes(x=V1, y=V2)) +  
  geom_point(size = 0.25) +
  geom_point(data = tsne_df.akt, aes(x=V1, y=V2, fill = class), col = "black", size = 2, shape = 23) +
  geom_point(data = tsne_df.mtor, aes(x=V1, y=V2, fill = class), col = "black", size = 2, shape = 23) +
  # geom_point(data = tsne_df.neg, fill = "yellow", size = 1, shape = 24) +
  guides(colour=guide_legend(override.aes=list(size=4))) +
  # scale_colour_brewer(palette = "Set2") +
  scale_fill_manual("Substrate", values = c("red", "magenta"), labels = c("Akt", "mTor")) +
  # scale_color_manual("DB Cluster", values = c("#669999", "#248f24", "#0000ff", "#e6e600")) +
  xlab("") + ylab("") +
  ggtitle("t-SNE 2 Dimentions Reduction overlay with XGB Predicted Akt & mTor") +
  theme_light(base_size=20) +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        plot.title = element_text(hjust = 0.5, size = 14),
        legend.title = element_text(color = "black", size = 12),
        legend.text = element_text(color = "black", size = 10)
  )
g3

```


### 10.7 Overlapping Random Forest Predicted Akt & mTor with tSNE Result
``` {r rftsneakt, message=FALSE, warning=FALSE}
getdata_for_tsne <- function(a, b) {
ins_df_with_neg <- ins_df_with_neg %>% inner_join(a) %>% 
  inner_join(b)
ins_ts_all <- ins_df_with_neg %>% dplyr::mutate(class = verdict + ifelse(is_mtor == 1, 2, 0)) %>% 
  dplyr::mutate(is_mtor = ifelse(verdict_m == 1, 2, 0), akt_neg_prob = ifelse(akt_neg_prob == 1, 0, 0),
         mtor_neg_prob = ifelse(mtor_neg_prob == 1, 0, 0)) %>% 
  dplyr::mutate (class = verdict + is_mtor + akt_neg_prob + mtor_neg_prob) %>% 
  select(id, motif_ti, class) %>% 
  dplyr::group_by(ti_pos01, ti_pos02, ti_pos03, ti_pos04, ti_pos05, ti_pos06, 
           ti_pos08, ti_pos09, ti_pos10, ti_pos11, ti_pos12, ti_pos13, ti_skip1_pos01, 
           ti_skip1_pos02, ti_skip1_pos03, ti_skip1_pos04, ti_skip1_pos05, 
           ti_skip1_pos06, ti_skip1_pos07, ti_skip1_pos08, ti_skip1_pos09, 
           ti_skip1_pos10, ti_skip1_pos11, ti_2gram_pos01, ti_2gram_pos02, 
           ti_2gram_pos03, ti_2gram_pos04, ti_2gram_pos05, ti_2gram_pos06, 
           ti_2gram_pos07, ti_2gram_pos08, ti_2gram_pos09, ti_2gram_pos10, 
           ti_2gram_pos11, ti_2gram_pos12) %>% 
  dplyr::mutate(rnum = row_number()) %>% 
  dplyr::ungroup()

# deduplicate data for tsne
ins_ts <-  ins_ts_all %>% dplyr::filter(rnum == 1)
return(ins_ts)
}

df_out <- read_csv("tsne_df_out.csv")
ins_df_with_neg <- read_csv("ins_df_with_neg_new.csv")

rf_a <- read_csv("AdaSampling_Akt_pred.csv", col_name = F) %>% 
  dplyr::rename(identifier = X1) %>% 
  dplyr::mutate(verdict = 1)

rf_a <- ins_df_with_neg %>% select(identifier) %>% left_join(rf_a) %>% 
  dplyr::mutate(verdict = ifelse(is.na(verdict), 0, 1))

rf_m <- read_csv("AdaSampling_mtor_pred.csv", col_name = F) %>% 
  dplyr::rename(identifier = X1) %>% 
  dplyr::mutate(verdict_m = 1)

rf_m <- ins_df_with_neg %>% select(identifier) %>% left_join(rf_m) %>% 
  dplyr::mutate(verdict_m = ifelse(is.na(verdict_m), 0, 1))

ins_ts <- getdata_for_tsne(rf_a, rf_m)
cl <- hdbscan(df_out, minPts = 10)
df_out <- df_out %>% bind_cols(data.frame(dbcl = cl$cluster, clprob = cl$membership_prob))

ins_ts_with_cluster <- ins_ts %>% bind_cols(data.frame(dbcluster = cl$cluster, 
                                                       cluster_prob = cl$membership_prob)) %>% 
  select(motif_ti, dbcluster, cluster_prob)

tsne_df <- bind_cols(df_out, ins_ts[, "class"]) %>%
  dplyr::mutate(dbcl = factor(dbcl), class = factor(class))

tsne_df.akt <- dplyr::filter(tsne_df, class == 1 | class == 3)
tsne_df.mtor <- dplyr::filter(tsne_df, class == 2 | class == 3)

## plot plain tsne output with Akt known
g2 <- ggplot(tsne_df, aes(x=V1, y=V2)) +  
  geom_point(size = 0.25) +
  geom_point(data = tsne_df.akt, aes(x=V1, y=V2), fill = "red", col = "black", size = 2, shape = 23) +
  # geom_point(data = tsne_df.mtor, aes(x=V1, y=V2, fill = class), col = "black", size = 4, shape = 23) +
  # geom_point(data = tsne_df.neg, fill = "yellow", size = 1, shape = 24) +
  guides(colour=guide_legend(override.aes=list(size=4))) +
  # scale_colour_brewer(palette = "Set2") +
  scale_fill_manual("Substrate", values = c("red"), labels = c("Akt")) +
  # scale_color_manual("DB Cluster", values = c("#669999", "#248f24", "#0000ff", "#e6e600")) +
  xlab("") + ylab("") +
  ggtitle("t-SNE 2 Dimentions Reduction overlay with RF Predicted Akt") +
  theme_light(base_size=20) +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        plot.title = element_text(hjust = 0.5, size = 16),
        legend.title = element_text(color = "black", size = 12),
        legend.text = element_text(color = "black", size = 10)
  )
g2

# for mTor
g3 <- ggplot(tsne_df, aes(x=V1, y=V2)) +  
  geom_point(size = 0.25) +
  # geom_point(data = tsne_df.akt, aes(x=V1, y=V2, fill = class), col = "black", size = 4, shape = 23) +
  geom_point(data = tsne_df.mtor, aes(x=V1, y=V2), col = "black", fill = "magenta", size = 2, shape = 23) +
  # geom_point(data = tsne_df.neg, fill = "yellow", size = 1, shape = 24) +
  guides(colour=guide_legend(override.aes=list(size=4))) +
  # scale_colour_brewer(palette = "Set2") +
  scale_fill_manual("Substrate", values = c("magenta"), labels = c("mTor")) +
  # scale_color_manual("DB Cluster", values = c("#669999", "#248f24", "#0000ff", "#e6e600")) +
  xlab("") + ylab("") +
  ggtitle("t-SNE 2 Dimentions Reduction overlay with RF Predicted mTor") +
  theme_light(base_size=20) +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        plot.title = element_text(hjust = 0.5, size = 16),
        legend.title = element_text(color = "black", size = 12),
        legend.text = element_text(color = "black", size = 10)
  )
g3

```


### 10.8 Overlapping SVM Predicted Akt & mTor with tSNE Result
``` {r rftsnemtor, message=FALSE, warning=FALSE}
df_out <- read_csv("tsne_df_out.csv")
ins_df_with_neg <- read_csv("ins_df_with_neg_new.csv")

svm_a <- read_csv("CorrFactor_Akt_pred.csv", col_name = F) %>% 
  dplyr::rename(identifier = X1) %>% 
  dplyr::mutate(verdict = 1)

svm_a <- ins_df_with_neg %>% select(identifier) %>% left_join(svm_a) %>% 
  dplyr::mutate(verdict = ifelse(is.na(verdict), 0, 1))

svm_m <- read_csv("CorrFactor_mTor_pred.csv", col_name = F) %>% 
  dplyr::rename(identifier = X1) %>% 
  dplyr::mutate(verdict_m = 1)

svm_m <- ins_df_with_neg %>% select(identifier) %>% left_join(svm_m) %>% 
  dplyr::mutate(verdict_m = ifelse(is.na(verdict_m), 0, 1))

ins_ts <- getdata_for_tsne(svm_a, svm_m)

cl <- hdbscan(df_out, minPts = 10)
df_out <- df_out %>% bind_cols(data.frame(dbcl = cl$cluster, clprob = cl$membership_prob))

ins_ts_with_cluster <- ins_ts %>% bind_cols(data.frame(dbcluster = cl$cluster, 
                                                       cluster_prob = cl$membership_prob)) %>% 
  select(motif_ti, dbcluster, cluster_prob)

tsne_df <- bind_cols(df_out, ins_ts[, "class"]) %>%
  dplyr::mutate(dbcl = factor(dbcl), class = factor(class))

tsne_df.akt <- dplyr::filter(tsne_df, class == 1 | class == 3)
tsne_df.mtor <- dplyr::filter(tsne_df, class == 2| class == 3)

## plot plain tsne output with Akt known
g2 <- ggplot(tsne_df, aes(x=V1, y=V2)) +  
  geom_point(size = 0.25) +
  geom_point(data = tsne_df.akt, aes(x=V1, y=V2), fill = "red", col = "black", size = 2, shape = 23) +
  # geom_point(data = tsne_df.mtor, aes(x=V1, y=V2, fill = class), col = "black", size = 4, shape = 23) +
  # geom_point(data = tsne_df.neg, fill = "yellow", size = 1, shape = 24) +
  guides(colour=guide_legend(override.aes=list(size=4))) +
  # scale_colour_brewer(palette = "Set2") +
  scale_fill_manual("Substrate", values = c("red"), labels = c("Akt")) +
  # scale_color_manual("DB Cluster", values = c("#669999", "#248f24", "#0000ff", "#e6e600")) +
  xlab("") + ylab("") +
  ggtitle("t-SNE 2 Dimentions Reduction overlay with SVM Predicted Akt") +
  theme_light(base_size=20) +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        plot.title = element_text(hjust = 0.5, size = 16),
        legend.title = element_text(color = "black", size = 12),
        legend.text = element_text(color = "black", size = 10)
  )
g2

### For mTor
g3 <- ggplot(tsne_df, aes(x=V1, y=V2)) +  
  geom_point(size = 0.25) +
  # geom_point(data = tsne_df.akt, aes(x=V1, y=V2, fill = class), col = "black", size = 4, shape = 23) +
  geom_point(data = tsne_df.mtor, aes(x=V1, y=V2), col = "black", fill = "magenta", size = 2, shape = 23) +
  # geom_point(data = tsne_df.neg, fill = "yellow", size = 1, shape = 24) +
  guides(colour=guide_legend(override.aes=list(size=4))) +
  # scale_colour_brewer(palette = "Set2") +
  scale_fill_manual("Substrate", values = c("magenta"), labels = c("mTor")) +
  # scale_color_manual("DB Cluster", values = c("#669999", "#248f24", "#0000ff", "#e6e600")) +
  xlab("") + ylab("") +
  ggtitle("t-SNE 2 Dimentions Reduction overlay with SVM Predicted mTor") +
  theme_light(base_size=20) +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        plot.title = element_text(hjust = 0.5, size = 16),
        legend.title = element_text(color = "black", size = 12),
        legend.text = element_text(color = "black", size = 10)
  )
g3

```


## 11. Reference

1. Yang, P., Humphrey, S., James, D., Yang, Y. and Jothi, R. (2016). Positive-unlabeled ensemble learning for kinase substrate prediction from dynamic phosphoproteomics data. Bioinformatics, 32(2), pp.252-259.
2. Pengyi Yang, Wei Liu, Jean Yang. (2017). Positive unlabeled learning via wrapper-based adaptive sampling. Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, Pages 3273-3279.
